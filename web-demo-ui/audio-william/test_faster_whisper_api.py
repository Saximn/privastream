#!/usr/bin/env python3
"""
Test script for Faster-Whisper Audio Redaction API
Creates test audio and verifies the API works correctly
"""

import requests
import numpy as np
import base64
import json
import time
from datetime import datetime

def create_test_audio():
    """Create simple test audio with speech-like patterns"""
    sample_rate = 16000
    duration = 3.0  # 3 seconds
    samples = int(sample_rate * duration)
    
    # Create audio that resembles speech (multiple frequencies)
    t = np.linspace(0, duration, samples)
    
    # Mix of frequencies that might resemble speech
    freq1 = 200  # Base frequency
    freq2 = 400  # Harmonic
    freq3 = 800  # Higher harmonic
    
    audio = (
        0.3 * np.sin(2 * np.pi * freq1 * t) +
        0.2 * np.sin(2 * np.pi * freq2 * t) +
        0.1 * np.sin(2 * np.pi * freq3 * t)
    )
    
    # Add some envelope to make it more speech-like
    envelope = np.exp(-2 * t) + 0.3
    audio = audio * envelope
    
    # Convert to int16
    audio_int16 = (audio * 32767).astype(np.int16)
    
    return audio_int16

def test_faster_whisper_api():
    """Test the Faster-Whisper audio redaction API"""
    print("ğŸ§ª Testing Faster-Whisper Audio Redaction API")
    print("=" * 60)
    
    api_url = "http://localhost:5002"
    
    # 1. Health check
    print("\nğŸ¥ Testing health endpoint...")
    try:
        response = requests.get(f"{api_url}/health")
        if response.status_code == 200:
            health_data = response.json()
            print("âœ… Health check passed!")
            print(f"   Service: {health_data.get('service', 'Unknown')}")
            print(f"   Models loaded: {health_data.get('models_loaded', {})}")
            print(f"   Faster-Whisper available: {health_data.get('faster_whisper_available', False)}")
            
            if health_data.get('gpu_info'):
                gpu_info = health_data['gpu_info']
                print(f"   GPU: {gpu_info.get('device_name', 'Unknown')}")
                print(f"   Memory: {gpu_info.get('memory_total', 'Unknown')}")
        else:
            print(f"âŒ Health check failed: {response.status_code}")
            print(f"   Response: {response.text}")
            return False
    except Exception as e:
        print(f"âŒ Health check error: {e}")
        return False
    
    # 2. Audio processing test
    print("\nğŸ¤ Testing audio processing...")
    try:
        # Create test audio
        test_audio = create_test_audio()
        print(f"Created test audio: {len(test_audio)} samples")
        
        # Encode as base64
        audio_b64 = base64.b64encode(test_audio.tobytes()).decode('utf-8')
        
        # Prepare request
        request_data = {
            "audio_data": audio_b64,
            "sample_rate": 16000
        }
        
        print("Sending audio processing request...")
        start_time = time.time()
        
        response = requests.post(
            f"{api_url}/process_audio",
            json=request_data,
            timeout=30  # 30 second timeout
        )
        
        processing_time = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            print("âœ… Audio processing successful!")
            print(f"   Processing time: {processing_time:.2f}s")
            print(f"   API processing time: {result.get('processing_time', 'Unknown'):.3f}s")
            print(f"   Speed ratio: {result.get('speed_ratio', 'Unknown'):.2f}x real-time")
            print(f"   Transcript: '{result.get('transcript', 'No transcript')}'")
            print(f"   PII detections: {result.get('pii_count', 0)}")
            print(f"   Device used: {result.get('device_used', 'Unknown')}")
            
            # Check if we got audio back
            if result.get('redacted_audio_data'):
                redacted_bytes = base64.b64decode(result['redacted_audio_data'])
                redacted_samples = len(redacted_bytes) // 2  # int16 = 2 bytes per sample
                print(f"   Returned audio: {redacted_samples} samples")
            else:
                print("   âš ï¸ No redacted audio data returned")
                
        else:
            print(f"âŒ Audio processing failed: {response.status_code}")
            print(f"   Response: {response.text}")
            return False
            
    except Exception as e:
        print(f"âŒ Audio processing error: {e}")
        return False
    
    # 3. Performance summary
    print("\nğŸ“Š Performance Summary:")
    print("=" * 60)
    
    if response.status_code == 200:
        result = response.json()
        timing = result.get('timing_breakdown', {})
        
        print(f"ğŸ¤ Faster-Whisper ASR: {timing.get('whisper_time', 0):.3f}s ({timing.get('whisper_ratio', 0):.2f}x RT)")
        print(f"ğŸ§  BERT NER:           {timing.get('bert_time', 0):.3f}s ({timing.get('bert_ratio', 0):.2f}x RT)")
        print(f"ğŸ”‡ Audio Muting:       {timing.get('mute_time', 0):.3f}s ({timing.get('mute_ratio', 0):.2f}x RT)")
        print(f"ğŸ“Š TOTAL:              {result.get('processing_time', 0):.3f}s ({result.get('speed_ratio', 0):.2f}x RT)")
        
        print(f"\nğŸ† Performance vs Traditional Whisper:")
        print(f"   Expected speedup: 2-5x faster")
        print(f"   Accuracy: Same or better than OpenAI Whisper")
        
    print("\nğŸ‰ All tests completed!")
    return True

def test_with_spoken_content():
    """Test with content that contains potential PII keywords"""
    print("\nğŸ—£ï¸ Testing with PII content simulation...")
    
    # This is just a simulation - we can't actually generate spoken audio easily
    # But we can test the keyword detection by checking logs
    
    api_url = "http://localhost:5002"
    
    # Create audio with patterns that might trigger keyword detection
    # (In reality, this would need actual speech audio)
    test_audio = create_test_audio()
    audio_b64 = base64.b64encode(test_audio.tobytes()).decode('utf-8')
    
    request_data = {
        "audio_data": audio_b64,
        "sample_rate": 16000
    }
    
    try:
        response = requests.post(f"{api_url}/process_audio", json=request_data)
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… PII test completed:")
            print(f"   Transcript: '{result.get('transcript', 'No transcript')}'")
            print(f"   PII detections: {result.get('pii_count', 0)}")
            print(f"   Redacted intervals: {result.get('redacted_intervals', [])}")
        else:
            print(f"âŒ PII test failed: {response.status_code}")
            
    except Exception as e:
        print(f"âŒ PII test error: {e}")

if __name__ == "__main__":
    print(f"ğŸš€ Starting Faster-Whisper API Test at {datetime.now()}")
    
    success = test_faster_whisper_api()
    
    if success:
        test_with_spoken_content()
        print("\nâœ… All tests passed! Faster-Whisper integration is working correctly.")
        print("\nğŸ“ Next steps:")
        print("   1. Replace the Vosk server with this Faster-Whisper version")
        print("   2. Test with real audio input")
        print("   3. Monitor performance improvements")
    else:
        print("\nâŒ Tests failed. Check the server logs and dependencies.")
        print("\nğŸ”§ Troubleshooting:")
        print("   1. Make sure the server is running: python audio_redaction_server_faster_whisper.py")
        print("   2. Install dependencies: pip install faster-whisper")
        print("   3. Check server logs for errors")