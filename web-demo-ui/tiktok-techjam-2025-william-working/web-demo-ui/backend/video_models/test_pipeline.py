"""
Test script for the Live Stream Pipeline.
Tests individual components and full pipeline integration.
"""

import sys
import time
import numpy as np
import cv2
from pathlib import Path

# Add current directory to path
sys.path.append(str(Path(__file__).parent))

from live_stream_pipeline import (
    LiveStreamPipeline, PipelineConfig, FrameBuffer, 
    PerformanceMonitor, FrameData
)


def test_frame_buffer():
    """Test the FrameBuffer class."""
    print("Testing FrameBuffer...")
    
    buffer = FrameBuffer(maxsize=3)
    
    # Create test frames
    test_frames = []
    for i in range(5):
        frame = FrameData(
            frame_id=i,
            timestamp=time.time(),
            image=np.random.randint(0, 255, (100, 100, 3), dtype=np.uint8)
        )
        test_frames.append(frame)
    
    # Test putting frames
    for i, frame in enumerate(test_frames):
        success = buffer.put(frame, block=False)
        print(f"  Put frame {i}: {'‚úì' if success else '‚úó'} (buffer size: {buffer.size()})")
    
    # Test getting frames
    while True:
        frame = buffer.get(block=False)
        if frame is None:
            break
        print(f"  Got frame {frame.frame_id}")
    
    print("  FrameBuffer test completed ‚úì\n")


def test_performance_monitor():
    """Test the PerformanceMonitor class."""
    print("Testing PerformanceMonitor...")
    
    config = PipelineConfig()
    monitor = PerformanceMonitor(config)
    
    # Simulate some processing
    for i in range(10):
        monitor.record_frame('input')
        time.sleep(0.01)  # 10ms processing time
        
        if i % 3 == 0:  # Process every 3rd frame
            monitor.record_frame('processed', 0.05)  # 50ms processing
            monitor.record_frame('output')
    
    stats = monitor.get_stats()
    print(f"  Frames: {stats['frames']}")
    print(f"  FPS estimates: {stats['fps']}")
    print(f"  Avg processing time: {stats['avg_processing_time_ms']:.1f}ms")
    print(f"  Efficiency: {stats['processing_efficiency']:.1f}%")
    print("  PerformanceMonitor test completed ‚úì\n")


def test_unified_detector():
    """Test the UnifiedBlurDetector."""
    print("Testing UnifiedBlurDetector...")
    
    try:
        from unified_detector import UnifiedBlurDetector
        
        # Create minimal config
        config = {
            "enable_face": True,
            "enable_pii": True, 
            "enable_plate": True
        }
        
        detector = UnifiedBlurDetector(config)
        print(f"  Loaded {len(detector.models)} models: {list(detector.models.keys())}")
        
        # Test with dummy frame
        test_frame = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
        results = detector.process_frame(test_frame, frame_id=0)
        
        print(f"  Detection results: {results['frame_id']}")
        for model_name, model_results in results.get('models', {}).items():
            if 'error' in model_results:
                print(f"    {model_name}: ERROR - {model_results['error']}")
            else:
                count = model_results.get('count', 0)
                print(f"    {model_name}: {count} detections")
        
        print("  UnifiedBlurDetector test completed ‚úì\n")
        
    except Exception as e:
        print(f"  UnifiedBlurDetector test failed: {e}\n")


def test_blur_utils():
    """Test the blur utility functions."""
    print("Testing blur utilities...")
    
    try:
        from blur_utils import apply_blur_regions
        
        # Create test image
        test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
        
        # Add some colored regions to see blur effect
        cv2.rectangle(test_image, (100, 100), (200, 200), (255, 0, 0), -1)
        
        # Test rectangle blur
        rectangles = [[100, 100, 200, 200]]
        blurred = apply_blur_regions(test_image.copy(), rectangles=rectangles)
        
        # Check if blur was applied (pixel values should be different)
        original_roi = test_image[100:200, 100:200]
        blurred_roi = blurred[100:200, 100:200]
        difference = np.mean(np.abs(original_roi.astype(float) - blurred_roi.astype(float)))
        
        print(f"  Rectangle blur applied: {'‚úì' if difference > 1.0 else '‚úó'} (diff: {difference:.2f})")
        
        # Test polygon blur
        polygon = np.array([[300, 300], [400, 300], [400, 400], [300, 400]], dtype=np.int32)
        polygons = [polygon]
        blurred_poly = apply_blur_regions(test_image.copy(), polygons=polygons)
        
        print("  Blur utilities test completed ‚úì\n")
        
    except Exception as e:
        print(f"  Blur utilities test failed: {e}\n")


def test_minimal_pipeline():
    """Test a minimal version of the pipeline."""
    print("Testing minimal pipeline setup...")
    
    try:
        # Create minimal config
        config = PipelineConfig(
            input_source=0,  # Webcam
            input_fps=10.0,  # Lower FPS for testing
            processing_fps=2.0,
            input_width=640,
            input_height=480,
            show_preview=False,  # No preview for automated test
            enable_profiling=False
        )
        
        print("  Configuration created ‚úì")
        
        # Create pipeline (but don't start it)
        pipeline = LiveStreamPipeline(config)
        print("  Pipeline created ‚úì")
        
        # Test that all components were initialized
        assert pipeline.input_buffer is not None
        assert pipeline.processing_buffer is not None
        assert pipeline.output_buffer is not None
        assert pipeline.video_scheduler is not None
        assert pipeline.video_analyzer is not None
        assert pipeline.blur_processor is not None
        
        print("  All components initialized ‚úì")
        print("  Minimal pipeline test completed ‚úì\n")
        
    except Exception as e:
        print(f"  Minimal pipeline test failed: {e}\n")


def run_quick_camera_test():
    """Quick test to verify camera access."""
    print("Testing camera access...")
    
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("  ‚úó Camera not accessible")
        return False
    
    ret, frame = cap.read()
    if not ret:
        print("  ‚úó Cannot read from camera")
        cap.release()
        return False
    
    height, width = frame.shape[:2]
    print(f"  ‚úì Camera accessible: {width}x{height}")
    
    cap.release()
    return True


def main():
    """Run all tests."""
    print("üß™ LIVE STREAM PIPELINE TESTS üß™")
    print("=" * 50)
    print()
    
    # Run individual component tests
    test_frame_buffer()
    test_performance_monitor()
    test_unified_detector()
    test_blur_utils()
    test_minimal_pipeline()
    
    # Quick camera test
    camera_ok = run_quick_camera_test()
    
    print("\n" + "=" * 50)
    print("TEST SUMMARY")
    print("=" * 50)
    print("‚úì FrameBuffer")
    print("‚úì PerformanceMonitor")
    print("? UnifiedBlurDetector (depends on model availability)")
    print("‚úì BlurUtilities")
    print("‚úì Pipeline Setup")
    print(f"{'‚úì' if camera_ok else '‚úó'} Camera Access")
    
    if camera_ok:
        print()
        print("üéâ All basic tests passed!")
        print("Ready to run the full pipeline with:")
        print("   python launch_pipeline.py")
    else:
        print()
        print("‚ö†Ô∏è  Camera not accessible - check camera permissions")
        print("   You can still test with a video file by changing INPUT_SOURCE")
        print("   in pipeline_config.py to a video file path")
    
    print()


if __name__ == "__main__":
    main()
